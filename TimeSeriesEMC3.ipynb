{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4abe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /proc/meminfo | grep Mem\n",
    "import psutil\n",
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad24f650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen libs\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "\n",
    "# libs for poincar√©\n",
    "from osa import Client\n",
    "\n",
    "# emc3 submodule\n",
    "import xemc3\n",
    "\n",
    "#vtk libs\n",
    "from tvtk.api import tvtk\n",
    "from mayavi.scripts import mayavi2\n",
    "from PyQt5 import QtCore\n",
    "import sip\n",
    "import vtk\n",
    "from mayavi import mlab\n",
    "%gui qt\n",
    "\n",
    "# importing widget libs to make interactive plots\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "import os\n",
    "import sys\n",
    "cwd = os.getcwd()\n",
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b8d874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary functions from the previous scripts\n",
    "loc_path_interpol_script = r\"~/w7x\"\n",
    "fps = []\n",
    "fps.append(loc_path_interpol_script + r\"\\grid.py\")\n",
    "fps.append(loc_path_interpol_script + r\"\\makemesh_indices.py\")\n",
    "for path in fps:\n",
    "    module_path = os.path.abspath(os.path.join(path))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af0d9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid import grid\n",
    "from makemesh_indices import make_parammesh_vtk_indices, from_indices_to_paramvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9384c6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_timeseriesdata_emc3 = r\"~/Dokumente/N01.nc\"\n",
    "ds_tot = xr.open_dataset(path_timeseriesdata_emc3)\n",
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5fd8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tsdata_emc3 = ds_tot.isel(time = slice(-20,None))\n",
    "del ds_tot\n",
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c52a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sel = ds_tsdata_emc3.mean(dim = 'time')\n",
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f4d082",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calc noise from mean\n",
    "ds_Te_noise = ds_tsdata_emc3.Te.copy()\n",
    "for i in range(20):\n",
    "    ds_Te_noise[i] = ds_tsdata_emc3.Te[i].copy() - mean_sel.Te.copy()\n",
    "ds_Te_denoised = ds_tsdata_emc3.Te.copy() - ds_Te_noise.copy()\n",
    "#ds_Te_noise.plot()\n",
    "#ds_Te_denoised.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bea1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_512 = grid(ds = ds_tsdata_emc3, ngrid_cart = 128, inc_r = [50, 140], inc_t = [0,513], inc_p = [0,36])\n",
    "dimgrid = list([x for x in grid_512.tor_x.shape[::-1]])\n",
    "sgrid_512 = tvtk.StructuredGrid(dimensions=dimgrid)\n",
    "del dimgrid\n",
    "sgrid_512.points = grid_512.torflat\n",
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ac3256",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxmesh, weightmesh = make_parammesh_vtk_indices(grid_obj = grid_512, \n",
    "                                                 sgrid = sgrid_512, \n",
    "                                                 sp = (0,0,0), \n",
    "                                                 tolsqrd = 5e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7170b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del sgrid_512\n",
    "with open('%s/timeseriesdata/idxmesh_%i.npy'%(cwd,idxmesh.shape[0]), 'wb') as f_i:\n",
    "    np.save(f_i, idxmesh)\n",
    "f_i.close()\n",
    "del idxmesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac4860d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s/timeseriesdata/weightmesh_%i.npy'%(cwd,weightmesh.shape[0]), 'wb') as f_w:\n",
    "    np.save(f_w, weightmesh)\n",
    "f_w.close()\n",
    "del weightmesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca80b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s/timeseriesdata/idxmesh_400.npy'%cwd, 'rb') as f_i:\n",
    "    idxmesh_load = np.load(f_i)\n",
    "f_i.close()\n",
    "with open('%s/timeseriesdata/weightmesh_400.npy'%cwd, 'rb') as f_w:\n",
    "    weightmesh_load = np.load(f_w)\n",
    "f_w.close()\n",
    "\n",
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f524437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_timeseries_data(idxs, weights, ds_param, sp = (0,0,0), str_size = '512'):\n",
    "    for i in range(ds_param.shape[0]):\n",
    "        ts = from_indices_to_paramvals(idxs = idxs,\n",
    "                                       weights = weights,\n",
    "                                       param_torgrid = np.asarray(ds_param[i]) )\n",
    "        with open('%s/timeseriesdata/ts_'%cwd+str_size+'_%s.npy'%i, 'wb') as f_ts:\n",
    "            np.save(f_ts, ts)\n",
    "        del ts\n",
    "        f_ts.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08852b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_timeseries_data(idxs = idxmesh_load, \n",
    "                     weights = weightmesh_load, \n",
    "                     ds_param = ds_Te_denoised[:,50:], \n",
    "                     sp = (0,0,0), str_size = '%i_denoised_wmean'%idxmesh_load.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b541bfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s/timeseriesdata/ts_400_denoised_wmean_0.npy'%cwd, 'rb') as f_ts:\n",
    "    t0 = np.load(f_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2a4197",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(t0[:,50].T[::-1])\n",
    "plt.colorbar()\n",
    "del t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3ca340",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#std_sel = ds_tsdata_emc3.std(dim = 'time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f5169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#std_tot = ds_tsdata_emc3.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0412f963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clientdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44532923",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.restoration import denoise_wavelet, cycle_spin\n",
    "from skimage import data, img_as_float\n",
    "from skimage.util import random_noise\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "import skimage.data\n",
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470f021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s/timeseriesdata/ts_400_orig_interpol.npy'%(cwd), 'rb') as f_ts:\n",
    "    pmesh_ts = np.load(f_ts)\n",
    "f_ts.close()\n",
    "\n",
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ae2d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shiftinv_wavelet_denoising(tsdata, int_y = [0,pmesh_ts[0][0].shape[1]]):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "     - tsdata, list of ndarray np.float64 (nt,)(nr,)(ix, iy, iz), list of times of list of regions of parameter mesh\n",
    "     - int_phi, list of int, defining the interval in phi direction\n",
    "    Out:\n",
    "    \"\"\"\n",
    "    tik = time.time()\n",
    "    denoised_t = []\n",
    "    for t in range(len(tsdata)):\n",
    "        img = tsdata[t].T[::-1,int_y[0]:int_y[1]].copy()\n",
    "        imgisnan = np.isnan(img)\n",
    "        img[imgisnan] = np.zeros(img[imgisnan].shape)\n",
    "        # multichannel = bool, do you have rgb/csv/hsv etc?, convert2ycbcr = bool, req multichannel = True\n",
    "        # denoise_kwargs = dict(multichannel=False, convert2ycbcr=False, wavelet='db1', rescale_sigma=True)\n",
    "        denoised = cycle_spin(img, func=denoise_wavelet, max_shifts=(4,4,4))#max_shifts=img.shape\n",
    "        del img\n",
    "        # set values that were nan before the denoising back to nan\n",
    "        denoised[imgisnan] = np.ones(denoised[imgisnan].shape)*np.nan\n",
    "        del imgisnan\n",
    "        denoised_t.append(denoised)\n",
    "        del denoised\n",
    "    tok = time.time()\n",
    "    return denoised_t, tok-tik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb81f33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emc3_denoised, runtime = shiftinv_wavelet_denoising(tsdata = pmesh_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284ddfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "emc3_denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dad97da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    with open('%s/timeseriesdata/ts_'%cwd+'%i_denoised_filter_%i.npy'%(emc3_denoised[0].shape[0], i), 'wb') as f_ts:\n",
    "                np.save(f_ts, emc3_denoised[i])\n",
    "f_ts.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8920c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(runtime)\n",
    "print(len(emc3_denoised))\n",
    "print(emc3_denoised[0].shape)\n",
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1048f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(emc3_denoised[0][:,60])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d07320",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(emc3_denoised[0][:,60] - pmesh_ts[0][:,60].T[::-1])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc238bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b826640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_regplot(ogimg, denoised_img):\n",
    "    fig, ax = plt.subplots(nrows = 2, ncols = 2, figsize = (20,20))\n",
    "    noisy = ax[0,0].imshow(ogimg)\n",
    "    ax[0,0].set_title(\"Noisy\")\n",
    "    fig.colorbar(noisy, ax = ax[0,0])\n",
    "    denoised = ax[0,1].imshow(denoised_img)\n",
    "    ax[0,1].set_title(\"Denoised\")\n",
    "    fig.colorbar(denoised, ax = ax[0,1])\n",
    "    noise = ax[1,0].imshow(ogimg - denoised_img)\n",
    "    ax[1,0].set_title(\"Noise\")\n",
    "    fig.colorbar(noise, ax = ax[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17236dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_noise(res, path = '%s/timeseriesdata'%os.getcwd(), b_mean = True, b_filter = False ):\n",
    "    with open('%s/ts_%i_orig_interpol.npy'%(path,res), 'rb') as f_og:\n",
    "        ts_og = np.load(f_og)\n",
    "    f_og.close()\n",
    "    print(psutil.virtual_memory())\n",
    "    if b_filter:\n",
    "        with open('%s/ts_%i_denoised.npy'%(path,res), 'rb') as f_filter:\n",
    "            ts_filter = np.load(f_filter)\n",
    "        f_filter.close()\n",
    "        for i in range(len(ts_og)):\n",
    "            noise_filter = ts_og[i].T[::-1] - ts_filter[i]\n",
    "            with open('%s/ts_%i_noise_filter_%i.npy'%(path,res,i), 'wb') as fn:\n",
    "                np.save(fn,noise_filter)\n",
    "            fn.close()\n",
    "            del noise_filter\n",
    "        del ts_filter\n",
    "    if b_mean:\n",
    "        with open('%s/ts_%i_denoised_wmean.npy'%(path,res), 'rb') as f_mean:\n",
    "            ts_mean = np.load(f_mean)\n",
    "        f_mean.close()\n",
    "        for i in range(len(ts_og)):\n",
    "            noise_mean = np.array(ts_og[i] - ts_mean[i]) \n",
    "            with open('%s/ts_%i_noise_mean_%i.npy'%(path,res, i), 'wb') as fn:\n",
    "                np.save(fn, noise_mean)\n",
    "                del noise_mean\n",
    "            fn.close()\n",
    "    del ts_og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0205a6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa5c39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_noise(res = 400, b_mean = False, b_filter = True)\n",
    "\n",
    "#del nfilter_400\n",
    "#del nmean_400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f34bea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ts_400_noise_mean = []\n",
    "for i in range(20):\n",
    "    with open('%s/timeseriesdata/ts_%i_noise_mean_%i.npy'%(cwd,400, i), 'rb') as fn:\n",
    "        ts_400_noise_mean.append(np.load(fn))\n",
    "    fn.close()\n",
    "fn.close()\n",
    "with open('%s/timeseriesdata/ts_%i_noise_mean.npy'%(cwd,400), 'wb') as fn:\n",
    "        np.save(fn, ts_400_noise_mean)\n",
    "fn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64034de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s/timeseriesdata/ts_%i_noise_mean_1.npy'%(cwd,400), 'rb') as fn:\n",
    "    nmean_400 = np.load(fn)\n",
    "fn.close()\n",
    "with open('%s/timeseriesdata/ts_%i_noise_filter_1.npy'%(cwd,400), 'rb') as fn:\n",
    "    nfilter_400 = np.load(fn)\n",
    "fn.close()\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(nfilter_400[:,5].T[::-1])\n",
    "plt.colorbar()\n",
    "\n",
    "#plt.plot(nmean_400.ravel(), nfilter_400.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aeb700",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s/timeseriesdata/ts_%i_noise_filter.npy'%(cwd,400), 'rb') as fn:\n",
    "    nfilter_400 = np.load(fn)\n",
    "fn.close()\n",
    "with open('%s/timeseriesdata/ts_%i_noise_mean.npy'%(cwd,400), 'rb') as fn:\n",
    "    nmean_400 = np.load(fn)\n",
    "fn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a0002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nfilter_400[0].shape)\n",
    "print(len(nfilter_400))\n",
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf35b90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "#for i in range(len(nfilter_400)):\n",
    "try:\n",
    "    plt.scatter(nfilter_400[1:2].ravel(), nmean_400[1:2].ravel())\n",
    "except MemoryError:\n",
    "    print(\"Ran out of memory.\")\n",
    "plt.xlabel('$\\\\theta_t - \\\\tilde{\\\\theta}$')\n",
    "plt.ylabel('$\\\\theta_t - \\\\hat{\\\\theta}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee49a466",
   "metadata": {},
   "source": [
    "# Updated plan:\n",
    "1. Compare filtering on whole dataset with effect of removing noise extracted from subtracting the mean from the dataset. Also compare the std and try to find other statistics to analyze the effect of the filter.\n",
    "2. Quantify/Identify the effect of the interpolation with regards to noise by using synthetic data where noise could be easily subtracted from the cartesian data after being added to the emc3-like data. The synthetic data should be set up as cos functions varying in several directions for theta and phi, and have som radial dependence.\n",
    "3. Do a spline fit in the toroidal direction for all parameter values centered at each cell. Compare with the current interpolation scheme?\n",
    "4. \n",
    "\n",
    "# Conservation of physical quantities\n",
    "\n",
    "1. Formulate the equations for the particle and heat flux balance.\n",
    "2. Implement the conservation equations.\n",
    "3. Confirm that the interpolation is conservation preserving.\n",
    "4. Quantify the error of conservation introduced by the interpolation?\n",
    "\n",
    "# The effect of noise with regards to the conservation of physical quantites\n",
    "1. Add independent noiseterms to each terms of the conservation equations and see how it affects the interpolated data.\n",
    "2. Apply the filtering to mean data + known noise terms to quantify the effect of the filtering method.\n",
    "3. Try and quantify when the conservation laws break down by increasing the noise contribution.\n",
    "4. Quantize the effect of the filtering method wiht regards to the conservation laws. How much does the filtering method increase the threshold of the noise contribution with regards to the preservation of conservation laws.\n",
    "\n",
    "# Decomposing the drift terms\n",
    "1. Formulate the equations of the drift terms.\n",
    "2. Split drift terms into divergence-free and non-divergence-free terms.\n",
    "3. Analyze the magnitude of the divergence-free terms. Give relative contribution measures to the $\\mathbf{E}\\times\\mathbf{B}$-terms.\n",
    "4. Give an analysis on whether to implement a divergence-free optimized interpolation scheme or not. If yes, go to the last step.\n",
    "\n",
    "# Implementing divergence-free property of interpolation scheme\n",
    "1. Generate synthetic divergence free field.\n",
    "2. Implement method for checking diverge-free property of the field.\n",
    "3. Investigate the effect that noise contribution has to the divergence-free property of the field and apply the filtering method on the synthetic field to give a measure on how the filtering method improves the preservation of the divergence-free property.\n",
    "4. By using the synthetic divergence-free field, implement a divergence-free interpolation method or optimize the already implemented method.\n",
    "5. Apply the divergence free interpolation on the raw emc3 data and confirm the divergence-free property of the relevant terms.\n",
    "6. Apply the filtering method and repeat step 5.\n",
    "7. Quantize the effect of the filter by comparing to the mean of the time series data.\n",
    "8. Do a bootstrap of the standard deviation to give a measure on the accuracy of the mean, and finally do a bias corrected estimate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a1661f",
   "metadata": {},
   "source": [
    "# Particle conservation\n",
    "\n",
    "## Generalized particle flux density conservation\n",
    "\n",
    "\\begin{equation}\n",
    "    \\nabla (n v) = S_p\n",
    "\\end{equation}\n",
    "\n",
    "where the particle source term $S_p$ is set to zero because it will only be non-zero in proximity of the targets. $n$ and $v$ is the particle density and fluid velocity so the resulting conservation equation is:\n",
    "\\begin{equation}\n",
    "\\nabla(nv) = 0\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\Gamma = -D \\frac{d n}{d \\mathbf{r}}\n",
    "\\end{equation}\n",
    "\n",
    "# Heat flux\n",
    "\n",
    "\\begin{align}\n",
    "q_{\\parallel} = -\\chi_n\\frac{dT_e}{d\\mathbf{r}}\n",
    "q_{\\perp} = K_eT_e^{5/2}\\frac{dT}{d\\mathbf{r}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f5f6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note M is the mach number of the parallell number\n",
    "mean_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94291e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,20))\n",
    "# mean_sel.emc3.plot_Rz('fort.46_0', phi = 0)\n",
    "gridlist_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b663b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_magneticfield(grid_obj):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "     - grid_obj, grid object\n",
    "    Out:\n",
    "     - Bmesh, ndarray np.float64, meshgrid of the magnetic field components\n",
    "    \"\"\"\n",
    "    config = tracer.types.MagneticConfig()\n",
    "    config.configIds = [0]\n",
    "\n",
    "    pos = tracer.types.Points3D()\n",
    "    pos.x1 = grid_obj.cartflat[:,0]\n",
    "    pos.x2 = grid_obj.cartflat[:,1]\n",
    "    pos.x3 = grid_obj.cartflat[:,2]\n",
    "\n",
    "    res = tracer.service.magneticField(pos, config)\n",
    "    B = np.zeros((3,) + pos.x1.shape)\n",
    "    B[0] = np.asarray(res.field.x1)\n",
    "    B[1] = np.asarray(res.field.x2)\n",
    "    B[2] = np.asarray(res.field.x3)\n",
    "#     print(B.shape)\n",
    "#     idx_othreshold = np.where( np.median(np.sqrt(np.sum(B**2, axis = 0)) ) < np.sqrt(np.sum(B**2, axis = 0)) )[0]\n",
    "#     print(np.sqrt(np.sum(B**2, axis = 0)).shape)\n",
    "#     idx_othreshold = np.where( np.sqrt(np.sum(B**2, axis = 0)) > 5 )[0]\n",
    "#     print(idx_othreshold.shape)\n",
    "#     B[:,idx_othreshold] = np.ones(B[:,idx_othreshold].shape)*np.nan\n",
    "    Bmesh = B.reshape((3,) + (grid_obj.cart_x.shape))\n",
    "    return Bmesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c41402",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = get_magneticfield(grid_obj = gridlist_timeseries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412ac780",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmeshreg = []\n",
    "for i in range(len(gridlist_timeseries)):\n",
    "    bmeshreg.append( get_magneticfield(grid_obj = gridlist_timeseries[i]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe80a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bmeshreg)\n",
    "bmeshreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe97e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlab.clf()\n",
    "mlab.quiver3d(gridlist_timeseries[0].cart_x, \n",
    "              gridlist_timeseries[0].cart_y, \n",
    "              gridlist_timeseries[0].cart_z, \n",
    "              bmeshreg[4][0], bmeshreg[4][1], bmeshreg[4][2])\n",
    "mlab.axes()\n",
    "mlab.scalarbar()\n",
    "mlab.outline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1e1058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj_gradparam_ontob(parammesh, b):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - parammesh, ndarray np.float64, cart coord, assuming scalar field\n",
    "    - b, ndarray np.float64, cart coord, magnetic unit vectors\n",
    "    Out:\n",
    "    - proj, ndarray np.float64, cart coord, the projection of the gradient onto the magnetic unit vectors\n",
    "    \"\"\"\n",
    "    grad = np.gradient(parammesh)\n",
    "    grad = np.array(grad)\n",
    "    print(grad.shape)\n",
    "    print(b.shape)\n",
    "    proj = np.nansum(grad*b, axis = 0)*b\n",
    "    return proj\n",
    "\n",
    "def decompose_parperp(parammesh, b):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - parammesh, ndarray np.float64, cart coord, assuming parammesh a scalar field\n",
    "    Out:\n",
    "    - paral, perp, ndarray np.float64, fieldline coords, \n",
    "      decomposed parallel and perpendicular comp of parammesh\n",
    "    \"\"\"\n",
    "    grad = np.gradient(parammesh)\n",
    "    paral = proj_gradparam_ontob(parammesh = parammesh, b = b)\n",
    "    perp = grad - paral\n",
    "    return paral, perp\n",
    "\n",
    "def calc_divergence(parammesh):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - parammesh, ndarray np.float64, cart coords, assuming vector field\n",
    "    Out:\n",
    "    - divergence of the vector field\n",
    "    \"\"\"\n",
    "    divcomp = [np.gradient(parammesh[i])[i] for i in range(3)]\n",
    "    return sum(divcomp) #Q: should I use nansum here??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a76cfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmesh_ts[0][0].shape\n",
    "bmeshreg[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce7d42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "projtest = proj_gradparam_ontob(parammesh = pmesh_ts[0][0], b = bmeshreg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1e93c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "projtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e249ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlab.clf()\n",
    "mlab.quiver3d(gridlist_timeseries[0].cart_x, \n",
    "              gridlist_timeseries[0].cart_y, \n",
    "              gridlist_timeseries[0].cart_z, \n",
    "              projtest[0], projtest[1], projtest[2])\n",
    "mlab.axes()\n",
    "mlab.scalarbar()\n",
    "mlab.outline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd55f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.constants\n",
    "def calc_electron_vel(machnumber, Te, Ti, m_i = scipy.constants.m_p):\n",
    "    return machnumber*np.sqrt((Te + Ti)/m_i)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6652777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here the interpolated values for M, Te and Ti shoudl be inserted instead of the means of the w7x griddata\n",
    "el_vel = calc_electron_vel(machnumber = mean_sel.M, Te = mean_sel.Te, Ti = mean_sel.Ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd2aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define a function(if necessary) that takes in electron velocity and electron density and calculates the\n",
    "gradient \\nabla(nv) which should be zero\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
